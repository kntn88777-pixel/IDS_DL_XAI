# ==================== TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU (HO√ÄN CH·ªàNH) ====================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder

import os # Th√™m th∆∞ vi·ªán os ƒë·ªÉ ki·ªÉm tra ƒë∆∞·ªùng d·∫´n

# ‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG:
# 1. Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n 'csv_file' v√† 'output_csv' cho ph√π h·ª£p v·ªõi m√°y t√≠nh c·ªßa b·∫°n.
# 2. ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t ƒë·ªß c√°c th∆∞ vi·ªán:
#    pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn

# =========================================================================

# 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu
# Vui l√≤ng thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y sang file CSV c·ªßa b·∫°n
csv_file = r"D:\\nienluan\data\\iot23.csv"  

# Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa file tr∆∞·ªõc khi ƒë·ªçc
if not os.path.exists(csv_file):
    print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file t·∫°i ƒë∆∞·ªùng d·∫´n: {csv_file}")
    print("Vui l√≤ng c·∫≠p nh·∫≠t bi·∫øn 'csv_file' v·ªõi ƒë∆∞·ªùng d·∫´n ch√≠nh x√°c.")
else:
    print("üîπ ƒêang ƒë·ªçc d·ªØ li·ªáu...")
    try:
        # S·ª≠ d·ª•ng low_memory=False cho c√°c file l·ªõn, tr√°nh c·∫£nh b√°o dtype
        df = pd.read_csv(csv_file, low_memory=False)
        
        # In th√¥ng tin c∆° b·∫£n v·ªÅ file
        so_dong_goc = df.shape[0]
        so_cot_goc = df.shape[1]
        print(f"‚úÖ ƒê·ªçc th√†nh c√¥ng: {so_dong_goc} d√≤ng, {so_cot_goc} c·ªôt (hay {so_cot_goc} ƒë·∫∑c tr∆∞ng)")

        # In t√™n c√°c ƒë·∫∑c tr∆∞ng (c·ªôt)
        print("\n**Danh s√°ch c√°c ƒë·∫∑c tr∆∞ng (c·ªôt):**")
        print(df.columns.tolist())
        print("-" * 50)
        
        # 2Ô∏è‚É£ L√†m s·∫°ch d·ªØ li·ªáu
        print("üîπ L√†m s·∫°ch d·ªØ li·ªáu...")
        # X√≥a c√°c d√≤ng c√≥ gi√° tr·ªã thi·∫øu (NaN)
        df.dropna(inplace=True) 
        # X√≥a c√°c d√≤ng tr√πng l·∫∑p
        df.drop_duplicates(inplace=True) 
        # ƒê·∫∑t l·∫°i ch·ªâ m·ª•c sau khi x√≥a d√≤ng
        df = df.reset_index(drop=True) 
        
        so_dong_sach = df.shape[0]
        so_cot_sach = df.shape[1]
        print(f"‚úÖ Sau l√†m s·∫°ch: {so_dong_sach} d√≤ng, {so_cot_sach} c·ªôt")

        # 3Ô∏è‚É£ X√°c ƒë·ªãnh c·ªôt nh√£n
        # Th·ª≠ t√¨m c·ªôt t√™n 'label', n·∫øu kh√¥ng c√≥ th√¨ l·∫•y c·ªôt cu·ªëi c√πng
        label_col = 'label' if 'label' in df.columns else df.columns[-1]
        print(f"üîπ C·ªôt nh√£n ƒë∆∞·ª£c s·ª≠ d·ª•ng: **{label_col}**")

        # 4Ô∏è‚É£ M√£ h√≥a t·∫•t c·∫£ c·ªôt kh√¥ng ph·∫£i s·ªë (Categorical/Object)
        print("üîπ M√£ h√≥a c√°c c·ªôt kh√¥ng ph·∫£i s·ªë...")
        for col in df.columns:
            # Ki·ªÉm tra ki·ªÉu d·ªØ li·ªáu l√† 'object' (th∆∞·ªùng l√† string/category trong pandas)
            if df[col].dtype == 'object':
                le = LabelEncoder()
                # Chuy·ªÉn sang string tr∆∞·ªõc khi m√£ h√≥a ƒë·ªÉ ƒë·∫£m b·∫£o LabelEncoder ho·∫°t ƒë·ªông
                df[col] = le.fit_transform(df[col].astype(str)) 
        print("‚úÖ Ho√†n t·∫•t m√£ h√≥a LabelEncoder")

        # 5Ô∏è‚É£ T√°ch d·ªØ li·ªáu & nh√£n
        # X l√† c√°c ƒë·∫∑c tr∆∞ng (features), y l√† nh√£n (target)
        X = df.drop(columns=[label_col])
        y = df[label_col]
        print(f"üîπ ƒê·∫∑c tr∆∞ng X c√≥ {X.shape[1]} c·ªôt (ƒë·∫∑c tr∆∞ng), Nh√£n y c√≥ {y.nunique()} l·ªõp.")

        # 6Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë (Ch·ªâ √°p d·ª•ng cho X)
        print("üîπ Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng StandardScaler...")
        scaler = StandardScaler()
        # √Åp d·ª•ng StandardScaler cho to√†n b·ªô d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng X
        X_scaled = scaler.fit_transform(X) 
        print("‚úÖ Chu·∫©n h√≥a ho√†n t·∫•t")

        # 7Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì tr∆∞·ªõc c√¢n b·∫±ng
        plt.figure(figsize=(7, 4))
        # S·ª≠ d·ª•ng countplot ƒë·ªÉ xem ph√¢n b·ªë c·ªßa nh√£n y
        sns.countplot(x=y) 
        plt.title("üìä Ph√¢n b·ªë nh√£n (tr∆∞·ªõc khi c√¢n b·∫±ng)")
        # Th√™m hi·ªÉn th·ªã gi√° tr·ªã tr√™n c√°c c·ªôt
        for container in plt.gca().containers:
            plt.bar_label(container)
        plt.show()

        # 8Ô∏è‚É£ C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng SMOTE (Oversampling)
        print("üîπ C√¢n b·∫±ng d·ªØ li·ªáu b·∫±ng SMOTE...")
        # S·ª≠ d·ª•ng SMOTE ƒë·ªÉ t·∫°o ra c√°c m·∫´u m·ªõi cho c√°c l·ªõp thi·ªÉu s·ªë
        smote = SMOTE(sampling_strategy='auto', random_state=42) 
        X_resampled, y_resampled = smote.fit_resample(X_scaled, y)
        print(f"‚úÖ Sau c√¢n b·∫±ng: {X_resampled.shape[0]} d√≤ng")

        # 9Ô∏è‚É£ V·∫Ω bi·ªÉu ƒë·ªì sau c√¢n b·∫±ng
        plt.figure(figsize=(7, 4))
        sns.countplot(x=y_resampled)
        plt.title("üìä Ph√¢n b·ªë nh√£n (sau khi c√¢n b·∫±ng)")
        # Th√™m hi·ªÉn th·ªã gi√° tr·ªã tr√™n c√°c c·ªôt
        for container in plt.gca().containers:
            plt.bar_label(container)
        plt.show()

        # üîü G·ªôp l·∫°i th√†nh DataFrame
        # Chuy·ªÉn d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a v√† c√¢n b·∫±ng tr·ªü l·∫°i th√†nh DataFrame
        df_balanced = pd.DataFrame(X_resampled, columns=X.columns)
        df_balanced[label_col] = y_resampled # Th√™m c·ªôt nh√£n ƒë√£ c√¢n b·∫±ng

        # 1Ô∏è‚É£1Ô∏è‚É£ Xu·∫•t ra file CSV (l∆∞u to√†n b·ªô)
        # Vui l√≤ng thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y sang n∆°i b·∫°n mu·ªën l∆∞u file
        output_csv = r"D:\\nienluancoso\data\\iot23_ba.csv" 
        
        # T·∫°o th∆∞ m·ª•c n·∫øu n√≥ ch∆∞a t·ªìn t·∫°i
        os.makedirs(os.path.dirname(output_csv), exist_ok=True)
        df_balanced.to_csv(output_csv, index=False)
        print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu c√¢n b·∫±ng v√†o: {output_csv}")

        # 1Ô∏è‚É£2Ô∏è‚É£ (Tu·ª≥ ch·ªçn) L∆∞u m·∫´u nh·ªè ƒë·ªÉ xem b·∫±ng Excel
        sample_excel = r"D:\\nienluancoso\data\\iot23_balan.xlsx"
        
        # T·∫°o th∆∞ m·ª•c n·∫øu n√≥ ch∆∞a t·ªìn t·∫°i
        os.makedirs(os.path.dirname(sample_excel), exist_ok=True)
        
        # L·∫•y m·∫´u ng·∫´u nhi√™n 500,000 d√≤ng
        if df_balanced.shape[0] >= 500_000:
            df_sample = df_balanced.sample(n=500_000, random_state=42)
        else:
            # N·∫øu √≠t h∆°n 500k d√≤ng, l∆∞u to√†n b·ªô
            df_sample = df_balanced
            print("‚ö†Ô∏è C·∫£nh b√°o: S·ªë d√≤ng sau c√¢n b·∫±ng √≠t h∆°n 500k, l∆∞u to√†n b·ªô v√†o file Excel m·∫´u.")

        df_sample.to_excel(sample_excel, index=False)
        print(f"‚úÖ ƒê√£ l∆∞u m·∫´u nh·ªè ({df_sample.shape[0]} d√≤ng) v√†o: {sample_excel}")

        print("\nüéØ **HO√ÄN T·∫§T TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU**")

    except Exception as e:
        print(f"‚ùå ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")